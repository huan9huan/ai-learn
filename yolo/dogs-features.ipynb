{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dogs feature data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dropout, Flatten, Dense, Conv2D, BatchNormalization, Activation, AveragePooling2D, concatenate, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.utils import Progbar, GeneratorEnqueuer\n",
    "from keras.applications import imagenet_utils\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import inspect\n",
    "import matplotlib.patches as patches\n",
    "import xml.etree.ElementTree as ET\n",
    "from utils import mkdirp, load_base, load_feature, anno_file_to_rect, anno_file_to_yolo_y, get_image_size, img2data, npy_file_x, npy_file_y\n",
    "from yolo_data_generator import YoloDataGenerator\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_root = \"/Users/xuan/work/dataset/dogs/images\"\n",
    "annotations_root = \"/Users/xuan/work/dataset/dogs/annotations\"\n",
    "\n",
    "train_images_root = images_root + \"/train\"\n",
    "val_images_root = images_root + \"/val\"\n",
    "train_annotations_root = annotations_root + \"/train\"\n",
    "val_annotations_root = annotations_root + \"/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the feature data\n",
    "round = .1\n",
    "nb_train_samples = NB_TRAIN_SAMPLES = int(16494 * round // 1) ## copy from split script\n",
    "nb_val_samples = NB_VAL_SAMPLES = int(4086 * round //1) ## copy from split script\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "n_classes = 120\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "base_model_name = \"mn\"\n",
    "GRIDS = {\"inception\": (5,5), \"mn\": (7,7)}\n",
    "grid = GRIDS[base_model_name]\n",
    "\n",
    "mkdirp(base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the feature map files if not yet generate before\n",
    "train_generator = YoloDataGenerator(train_images_root, train_annotations_root, grid = grid)\n",
    "val_generator = YoloDataGenerator(val_images_root, val_annotations_root, grid = grid)\n",
    "\n",
    "def generate_features(generator, processor, model, total_samples, output_dir, prefix, batch_size = 16):\n",
    "    steps = 1\n",
    "    enqueuer = GeneratorEnqueuer(generator)\n",
    "    feature_file = npy_file_x(output_dir, prefix)\n",
    "    label_file = npy_file_y(output_dir, prefix)\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    batch_nums = total_samples//batch_size\n",
    "    progbar = Progbar(target=batch_nums)\n",
    "    \n",
    "    enqueuer.start()\n",
    "    output_generator = enqueuer.get()\n",
    "    \n",
    "    for b in range(0, batch_nums):\n",
    "      batch_x, batch_labels = next(output_generator) ## 从原始数据中拉取一批数据\n",
    "      feature = model.predict(processor(batch_x), batch_size = batch_size) # 根据数据提取feature\n",
    "      all_labels.append(batch_labels)\n",
    "      all_features.append(feature)\n",
    "      steps += 1\n",
    "      progbar.update(steps)\n",
    "\n",
    "    all_features = np.concatenate(all_features)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    print \"Round {} finished, saved to features {} (shapes {}) labels {} (shape {})\".format(round, feature_file, all_features.shape, label_file, all_labels.shape)\n",
    "    \n",
    "    np.save(open(feature_file, 'w'), all_features)\n",
    "    np.save(open(label_file, 'w'), all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load the base model done mn\n",
      "25/25 [==============================] - 34s 1s/step\n",
      "26/25 [===============================] - 35s 1s/step\n",
      "Round 0.1 finished, saved to features mn/val-dogs-120.x.npy (shapes (400, 7, 7, 1024)) labels mn/val-dogs-120.y.npy (shape (400, 245))\n",
      "103/103 [==============================] - 157s 2s/step\n",
      "104/103 [==============================] - 159s 2s/step\n",
      "Round 0.1 finished, saved to features mn/train-dogs-120.x.npy (shapes (1648, 7, 7, 1024)) labels mn/train-dogs-120.y.npy (shape (1648, 245))\n"
     ]
    }
   ],
   "source": [
    "# generate the features\n",
    "base_model, base_decoder, processor = load_base(base_model_name)\n",
    "for layer in base_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "print \"load the base model done\", base_model_name\n",
    "generate_features(val_generator.generate(), processor, base_model, nb_val_samples, base_model_name, \"val-dogs-120\")\n",
    "generate_features(train_generator.generate(), processor, base_model, nb_train_samples, base_model_name, \"train-dogs-120\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
