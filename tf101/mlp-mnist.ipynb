{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep nn with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist = input_data.read_data_sets('../data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK ready!\n"
     ]
    }
   ],
   "source": [
    "n_input = 28 * 28 * 1 ## n_height = n_width = 28, n_c = 1\n",
    "n_l1 = 128 ## layer 1 node count\n",
    "\n",
    "n_classes = 10 ## the output class count, the softmax output\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[n_input, None])\n",
    "y = tf.placeholder(tf.float32, shape=[n_classes, None])\n",
    "\n",
    "w1 = tf.Variable(tf.zeros([n_l1, n_input]))\n",
    "b1 = tf.Variable(tf.zeros([n_l1, 1]))\n",
    "\n",
    "w2 = tf.Variable(tf.zeros([n_classes, n_l1]))\n",
    "b2 = tf.Variable(tf.zeros([n_classes, 1]))\n",
    "\n",
    "print \"NETWORK ready!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z(X, W, b):\n",
    "    return tf.add(tf.matmul(W, X),  b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient decent is ready\n"
     ]
    }
   ],
   "source": [
    "## define the graph\n",
    "z1 = z(x, w1, b1)\n",
    "a1 = tf.nn.relu(z1)\n",
    "\n",
    "z2 = z(a1, w2, b2)\n",
    "y_ = tf.nn.softmax(z2)\n",
    "\n",
    "learning_rate = 0.5\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_, labels=y))\n",
    "# optm = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "optm = tf.train.AdamOptimizer(learning_rate=0.5).minimize(cost)\n",
    "corr = tf.equal(tf.argmax(y_, 0), tf.argmax(y, 0))\n",
    "accr = tf.reduce_mean(tf.cast(corr, tf.float32))\n",
    "\n",
    "# initialize\n",
    "init = tf.global_variables_initializer()\n",
    "print \"gradient decent is ready\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 2)\n",
      "[[ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 1.  1.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "test images, X, y shape\n",
      "(784, 10000)\n",
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "batch_xs, batch_ys = mnist.train.next_batch(2)\n",
    "print batch_xs.T.shape\n",
    "print batch_ys.T\n",
    "print \"test images, X, y shape\"\n",
    "print mnist.test.images.T.shape\n",
    "print mnist.test.labels.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init run done\n",
      "total batch  429\n",
      "#Epoch  0\n",
      "#Epoch  1\n",
      "#Epoch  2\n",
      "#Epoch  3\n",
      "#Epoch  4\n",
      "Epoch: 004/500 cost: 62.105986268\n",
      "TRAIN ACCURACY: 0.141\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  5\n",
      "#Epoch  6\n",
      "#Epoch  7\n",
      "#Epoch  8\n",
      "#Epoch  9\n",
      "Epoch: 009/500 cost: 62.105986571\n",
      "TRAIN ACCURACY: 0.125\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  10\n",
      "#Epoch  11\n",
      "#Epoch  12\n",
      "#Epoch  13\n",
      "#Epoch  14\n",
      "Epoch: 014/500 cost: 62.105986126\n",
      "TRAIN ACCURACY: 0.055\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  15\n",
      "#Epoch  16\n",
      "#Epoch  17\n",
      "#Epoch  18\n",
      "#Epoch  19\n",
      "Epoch: 019/500 cost: 62.105986482\n",
      "TRAIN ACCURACY: 0.086\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  20\n",
      "#Epoch  21\n",
      "#Epoch  22\n",
      "#Epoch  23\n",
      "#Epoch  24\n",
      "Epoch: 024/500 cost: 62.105986251\n",
      "TRAIN ACCURACY: 0.102\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  25\n",
      "#Epoch  26\n",
      "#Epoch  27\n",
      "#Epoch  28\n",
      "#Epoch  29\n",
      "Epoch: 029/500 cost: 62.105986375\n",
      "TRAIN ACCURACY: 0.109\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  30\n",
      "#Epoch  31\n",
      "#Epoch  32\n",
      "#Epoch  33\n",
      "#Epoch  34\n",
      "Epoch: 034/500 cost: 62.105986197\n",
      "TRAIN ACCURACY: 0.125\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  35\n",
      "#Epoch  36\n",
      "#Epoch  37\n",
      "#Epoch  38\n",
      "#Epoch  39\n",
      "Epoch: 039/500 cost: 62.105986535\n",
      "TRAIN ACCURACY: 0.117\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  40\n",
      "#Epoch  41\n",
      "#Epoch  42\n",
      "#Epoch  43\n",
      "#Epoch  44\n",
      "Epoch: 044/500 cost: 62.105986268\n",
      "TRAIN ACCURACY: 0.078\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  45\n",
      "#Epoch  46\n",
      "#Epoch  47\n",
      "#Epoch  48\n",
      "#Epoch  49\n",
      "Epoch: 049/500 cost: 62.105986304\n",
      "TRAIN ACCURACY: 0.086\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  50\n",
      "#Epoch  51\n",
      "#Epoch  52\n",
      "#Epoch  53\n",
      "#Epoch  54\n",
      "Epoch: 054/500 cost: 62.105986482\n",
      "TRAIN ACCURACY: 0.141\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  55\n",
      "#Epoch  56\n",
      "#Epoch  57\n",
      "#Epoch  58\n",
      "#Epoch  59\n",
      "Epoch: 059/500 cost: 62.105986428\n",
      "TRAIN ACCURACY: 0.102\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  60\n",
      "#Epoch  61\n",
      "#Epoch  62\n",
      "#Epoch  63\n",
      "#Epoch  64\n",
      "Epoch: 064/500 cost: 62.105986268\n",
      "TRAIN ACCURACY: 0.133\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  65\n",
      "#Epoch  66\n",
      "#Epoch  67\n",
      "#Epoch  68\n",
      "#Epoch  69\n",
      "Epoch: 069/500 cost: 62.105986482\n",
      "TRAIN ACCURACY: 0.109\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  70\n",
      "#Epoch  71\n",
      "#Epoch  72\n",
      "#Epoch  73\n",
      "#Epoch  74\n",
      "Epoch: 074/500 cost: 62.105986464\n",
      "TRAIN ACCURACY: 0.117\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  75\n",
      "#Epoch  76\n",
      "#Epoch  77\n",
      "#Epoch  78\n",
      "#Epoch  79\n",
      "Epoch: 079/500 cost: 62.105986286\n",
      "TRAIN ACCURACY: 0.094\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  80\n",
      "#Epoch  81\n",
      "#Epoch  82\n",
      "#Epoch  83\n",
      "#Epoch  84\n",
      "Epoch: 084/500 cost: 62.105986713\n",
      "TRAIN ACCURACY: 0.141\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  85\n",
      "#Epoch  86\n",
      "#Epoch  87\n",
      "#Epoch  88\n",
      "#Epoch  89\n",
      "Epoch: 089/500 cost: 62.105986197\n",
      "TRAIN ACCURACY: 0.148\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  90\n",
      "#Epoch  91\n",
      "#Epoch  92\n",
      "#Epoch  93\n",
      "#Epoch  94\n",
      "Epoch: 094/500 cost: 62.105986873\n",
      "TRAIN ACCURACY: 0.133\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  95\n",
      "#Epoch  96\n",
      "#Epoch  97\n",
      "#Epoch  98\n",
      "#Epoch  99\n",
      "Epoch: 099/500 cost: 62.105986464\n",
      "TRAIN ACCURACY: 0.148\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  100\n",
      "#Epoch  101\n",
      "#Epoch  102\n",
      "#Epoch  103\n",
      "#Epoch  104\n",
      "Epoch: 104/500 cost: 62.105986446\n",
      "TRAIN ACCURACY: 0.070\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  105\n",
      "#Epoch  106\n",
      "#Epoch  107\n",
      "#Epoch  108\n",
      "#Epoch  109\n",
      "Epoch: 109/500 cost: 62.105986606\n",
      "TRAIN ACCURACY: 0.094\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  110\n",
      "#Epoch  111\n",
      "#Epoch  112\n",
      "#Epoch  113\n",
      "#Epoch  114\n",
      "Epoch: 114/500 cost: 62.105986357\n",
      "TRAIN ACCURACY: 0.117\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  115\n",
      "#Epoch  116\n",
      "#Epoch  117\n",
      "#Epoch  118\n",
      "#Epoch  119\n",
      "Epoch: 119/500 cost: 62.105986375\n",
      "TRAIN ACCURACY: 0.094\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  120\n",
      "#Epoch  121\n",
      "#Epoch  122\n",
      "#Epoch  123\n",
      "#Epoch  124\n",
      "Epoch: 124/500 cost: 62.105986411\n",
      "TRAIN ACCURACY: 0.117\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  125\n",
      "#Epoch  126\n",
      "#Epoch  127\n",
      "#Epoch  128\n",
      "#Epoch  129\n",
      "Epoch: 129/500 cost: 62.105986428\n",
      "TRAIN ACCURACY: 0.117\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  130\n",
      "#Epoch  131\n",
      "#Epoch  132\n",
      "#Epoch  133\n",
      "#Epoch  134\n",
      "Epoch: 134/500 cost: 62.105986535\n",
      "TRAIN ACCURACY: 0.125\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  135\n",
      "#Epoch  136\n",
      "#Epoch  137\n",
      "#Epoch  138\n",
      "#Epoch  139\n",
      "Epoch: 139/500 cost: 62.105986304\n",
      "TRAIN ACCURACY: 0.086\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  140\n",
      "#Epoch  141\n",
      "#Epoch  142\n",
      "#Epoch  143\n",
      "#Epoch  144\n",
      "Epoch: 144/500 cost: 62.105986340\n",
      "TRAIN ACCURACY: 0.109\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  145\n",
      "#Epoch  146\n",
      "#Epoch  147\n",
      "#Epoch  148\n",
      "#Epoch  149\n",
      "Epoch: 149/500 cost: 62.105986375\n",
      "TRAIN ACCURACY: 0.117\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  150\n",
      "#Epoch  151\n",
      "#Epoch  152\n",
      "#Epoch  153\n",
      "#Epoch  154\n",
      "Epoch: 154/500 cost: 62.105986375\n",
      "TRAIN ACCURACY: 0.078\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  155\n",
      "#Epoch  156\n",
      "#Epoch  157\n",
      "#Epoch  158\n",
      "#Epoch  159\n",
      "Epoch: 159/500 cost: 62.105986535\n",
      "TRAIN ACCURACY: 0.094\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  160\n",
      "#Epoch  161\n",
      "#Epoch  162\n",
      "#Epoch  163\n",
      "#Epoch  164\n",
      "Epoch: 164/500 cost: 62.105986251\n",
      "TRAIN ACCURACY: 0.102\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  165\n",
      "#Epoch  166\n",
      "#Epoch  167\n",
      "#Epoch  168\n",
      "#Epoch  169\n",
      "Epoch: 169/500 cost: 62.105986517\n",
      "TRAIN ACCURACY: 0.141\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  170\n",
      "#Epoch  171\n",
      "#Epoch  172\n",
      "#Epoch  173\n",
      "#Epoch  174\n",
      "Epoch: 174/500 cost: 62.105986340\n",
      "TRAIN ACCURACY: 0.023\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  175\n",
      "#Epoch  176\n",
      "#Epoch  177\n",
      "#Epoch  178\n",
      "#Epoch  179\n",
      "Epoch: 179/500 cost: 62.105986215\n",
      "TRAIN ACCURACY: 0.094\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  180\n",
      "#Epoch  181\n",
      "#Epoch  182\n",
      "#Epoch  183\n",
      "#Epoch  184\n",
      "Epoch: 184/500 cost: 62.105986179\n",
      "TRAIN ACCURACY: 0.078\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  185\n",
      "#Epoch  186\n",
      "#Epoch  187\n",
      "#Epoch  188\n",
      "#Epoch  189\n",
      "Epoch: 189/500 cost: 62.105986446\n",
      "TRAIN ACCURACY: 0.125\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  190\n",
      "#Epoch  191\n",
      "#Epoch  192\n",
      "#Epoch  193\n",
      "#Epoch  194\n",
      "Epoch: 194/500 cost: 62.105986482\n",
      "TRAIN ACCURACY: 0.070\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  195\n",
      "#Epoch  196\n",
      "#Epoch  197\n",
      "#Epoch  198\n",
      "#Epoch  199\n",
      "Epoch: 199/500 cost: 62.105986553\n",
      "TRAIN ACCURACY: 0.125\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  200\n",
      "#Epoch  201\n",
      "#Epoch  202\n",
      "#Epoch  203\n",
      "#Epoch  204\n",
      "Epoch: 204/500 cost: 62.105986108\n",
      "TRAIN ACCURACY: 0.078\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  205\n",
      "#Epoch  206\n",
      "#Epoch  207\n",
      "#Epoch  208\n",
      "#Epoch  209\n",
      "Epoch: 209/500 cost: 62.105986179\n",
      "TRAIN ACCURACY: 0.125\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  210\n",
      "#Epoch  211\n",
      "#Epoch  212\n",
      "#Epoch  213\n",
      "#Epoch  214\n",
      "Epoch: 214/500 cost: 62.105986002\n",
      "TRAIN ACCURACY: 0.133\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  215\n",
      "#Epoch  216\n",
      "#Epoch  217\n",
      "#Epoch  218\n",
      "#Epoch  219\n",
      "Epoch: 219/500 cost: 62.105986144\n",
      "TRAIN ACCURACY: 0.117\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  220\n",
      "#Epoch  221\n",
      "#Epoch  222\n",
      "#Epoch  223\n",
      "#Epoch  224\n",
      "Epoch: 224/500 cost: 62.105986162\n",
      "TRAIN ACCURACY: 0.125\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  225\n",
      "#Epoch  226\n",
      "#Epoch  227\n",
      "#Epoch  228\n",
      "#Epoch  229\n",
      "Epoch: 229/500 cost: 62.105986108\n",
      "TRAIN ACCURACY: 0.078\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  230\n",
      "#Epoch  231\n",
      "#Epoch  232\n",
      "#Epoch  233\n",
      "#Epoch  234\n",
      "Epoch: 234/500 cost: 62.105986162\n",
      "TRAIN ACCURACY: 0.078\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  235\n",
      "#Epoch  236\n",
      "#Epoch  237\n",
      "#Epoch  238\n",
      "#Epoch  239\n",
      "Epoch: 239/500 cost: 62.105986251\n",
      "TRAIN ACCURACY: 0.102\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  240\n",
      "#Epoch  241\n",
      "#Epoch  242\n",
      "#Epoch  243\n",
      "#Epoch  244\n",
      "Epoch: 244/500 cost: 62.105986393\n",
      "TRAIN ACCURACY: 0.109\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  245\n",
      "#Epoch  246\n",
      "#Epoch  247\n",
      "#Epoch  248\n",
      "#Epoch  249\n",
      "Epoch: 249/500 cost: 62.105986126\n",
      "TRAIN ACCURACY: 0.109\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  250\n",
      "#Epoch  251\n",
      "#Epoch  252\n",
      "#Epoch  253\n",
      "#Epoch  254\n",
      "Epoch: 254/500 cost: 62.105986500\n",
      "TRAIN ACCURACY: 0.141\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  255\n",
      "#Epoch  256\n",
      "#Epoch  257\n",
      "#Epoch  258\n",
      "#Epoch  259\n",
      "Epoch: 259/500 cost: 62.105986375\n",
      "TRAIN ACCURACY: 0.086\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  260\n",
      "#Epoch  261\n",
      "#Epoch  262\n",
      "#Epoch  263\n",
      "#Epoch  264\n",
      "Epoch: 264/500 cost: 62.105986731\n",
      "TRAIN ACCURACY: 0.102\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  265\n",
      "#Epoch  266\n",
      "#Epoch  267\n",
      "#Epoch  268\n",
      "#Epoch  269\n",
      "Epoch: 269/500 cost: 62.105986340\n",
      "TRAIN ACCURACY: 0.133\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  270\n",
      "#Epoch  271\n",
      "#Epoch  272\n",
      "#Epoch  273\n",
      "#Epoch  274\n",
      "Epoch: 274/500 cost: 62.105986340\n",
      "TRAIN ACCURACY: 0.117\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  275\n",
      "#Epoch  276\n",
      "#Epoch  277\n",
      "#Epoch  278\n",
      "#Epoch  279\n",
      "Epoch: 279/500 cost: 62.105986304\n",
      "TRAIN ACCURACY: 0.125\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  280\n",
      "#Epoch  281\n",
      "#Epoch  282\n",
      "#Epoch  283\n",
      "#Epoch  284\n",
      "Epoch: 284/500 cost: 62.105986500\n",
      "TRAIN ACCURACY: 0.109\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  285\n",
      "#Epoch  286\n",
      "#Epoch  287\n",
      "#Epoch  288\n",
      "#Epoch  289\n",
      "Epoch: 289/500 cost: 62.105986375\n",
      "TRAIN ACCURACY: 0.094\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  290\n",
      "#Epoch  291\n",
      "#Epoch  292\n",
      "#Epoch  293\n",
      "#Epoch  294\n",
      "Epoch: 294/500 cost: 62.105986126\n",
      "TRAIN ACCURACY: 0.109\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  295\n",
      "#Epoch  296\n",
      "#Epoch  297\n",
      "#Epoch  298\n",
      "#Epoch  299\n",
      "Epoch: 299/500 cost: 62.105986606\n",
      "TRAIN ACCURACY: 0.102\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  300\n",
      "#Epoch  301\n",
      "#Epoch  302\n",
      "#Epoch  303\n",
      "#Epoch  304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 304/500 cost: 62.105986500\n",
      "TRAIN ACCURACY: 0.164\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  305\n",
      "#Epoch  306\n",
      "#Epoch  307\n",
      "#Epoch  308\n",
      "#Epoch  309\n",
      "Epoch: 309/500 cost: 62.105986197\n",
      "TRAIN ACCURACY: 0.094\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  310\n",
      "#Epoch  311\n",
      "#Epoch  312\n",
      "#Epoch  313\n",
      "#Epoch  314\n",
      "Epoch: 314/500 cost: 62.105986162\n",
      "TRAIN ACCURACY: 0.086\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  315\n",
      "#Epoch  316\n",
      "#Epoch  317\n",
      "#Epoch  318\n",
      "#Epoch  319\n",
      "Epoch: 319/500 cost: 62.105986322\n",
      "TRAIN ACCURACY: 0.070\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  320\n",
      "#Epoch  321\n",
      "#Epoch  322\n",
      "#Epoch  323\n",
      "#Epoch  324\n",
      "Epoch: 324/500 cost: 62.105986108\n",
      "TRAIN ACCURACY: 0.125\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  325\n",
      "#Epoch  326\n",
      "#Epoch  327\n",
      "#Epoch  328\n",
      "#Epoch  329\n",
      "Epoch: 329/500 cost: 62.105986553\n",
      "TRAIN ACCURACY: 0.164\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  330\n",
      "#Epoch  331\n",
      "#Epoch  332\n",
      "#Epoch  333\n",
      "#Epoch  334\n",
      "Epoch: 334/500 cost: 62.105986268\n",
      "TRAIN ACCURACY: 0.102\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  335\n",
      "#Epoch  336\n",
      "#Epoch  337\n",
      "#Epoch  338\n",
      "#Epoch  339\n",
      "Epoch: 339/500 cost: 62.105986340\n",
      "TRAIN ACCURACY: 0.102\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  340\n",
      "#Epoch  341\n",
      "#Epoch  342\n",
      "#Epoch  343\n",
      "#Epoch  344\n",
      "Epoch: 344/500 cost: 62.105986144\n",
      "TRAIN ACCURACY: 0.102\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  345\n",
      "#Epoch  346\n",
      "#Epoch  347\n",
      "#Epoch  348\n",
      "#Epoch  349\n",
      "Epoch: 349/500 cost: 62.105986411\n",
      "TRAIN ACCURACY: 0.102\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  350\n",
      "#Epoch  351\n",
      "#Epoch  352\n",
      "#Epoch  353\n",
      "#Epoch  354\n",
      "Epoch: 354/500 cost: 62.105986500\n",
      "TRAIN ACCURACY: 0.078\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  355\n",
      "#Epoch  356\n",
      "#Epoch  357\n",
      "#Epoch  358\n",
      "#Epoch  359\n",
      "Epoch: 359/500 cost: 62.105986340\n",
      "TRAIN ACCURACY: 0.102\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  360\n",
      "#Epoch  361\n",
      "#Epoch  362\n",
      "#Epoch  363\n",
      "#Epoch  364\n",
      "Epoch: 364/500 cost: 62.105986197\n",
      "TRAIN ACCURACY: 0.141\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  365\n",
      "#Epoch  366\n",
      "#Epoch  367\n",
      "#Epoch  368\n",
      "#Epoch  369\n",
      "Epoch: 369/500 cost: 62.105986677\n",
      "TRAIN ACCURACY: 0.117\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  370\n",
      "#Epoch  371\n",
      "#Epoch  372\n",
      "#Epoch  373\n",
      "#Epoch  374\n",
      "Epoch: 374/500 cost: 62.105986340\n",
      "TRAIN ACCURACY: 0.094\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  375\n",
      "#Epoch  376\n",
      "#Epoch  377\n",
      "#Epoch  378\n",
      "#Epoch  379\n",
      "Epoch: 379/500 cost: 62.105986340\n",
      "TRAIN ACCURACY: 0.156\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  380\n",
      "#Epoch  381\n",
      "#Epoch  382\n",
      "#Epoch  383\n",
      "#Epoch  384\n",
      "Epoch: 384/500 cost: 62.105986517\n",
      "TRAIN ACCURACY: 0.102\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  385\n",
      "#Epoch  386\n",
      "#Epoch  387\n",
      "#Epoch  388\n",
      "#Epoch  389\n",
      "Epoch: 389/500 cost: 62.105986446\n",
      "TRAIN ACCURACY: 0.148\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  390\n",
      "#Epoch  391\n",
      "#Epoch  392\n",
      "#Epoch  393\n",
      "#Epoch  394\n",
      "Epoch: 394/500 cost: 62.105986268\n",
      "TRAIN ACCURACY: 0.156\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  395\n",
      "#Epoch  396\n",
      "#Epoch  397\n",
      "#Epoch  398\n",
      "#Epoch  399\n",
      "Epoch: 399/500 cost: 62.105986304\n",
      "TRAIN ACCURACY: 0.055\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  400\n",
      "#Epoch  401\n",
      "#Epoch  402\n",
      "#Epoch  403\n",
      "#Epoch  404\n",
      "Epoch: 404/500 cost: 62.105986340\n",
      "TRAIN ACCURACY: 0.062\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  405\n",
      "#Epoch  406\n",
      "#Epoch  407\n",
      "#Epoch  408\n",
      "#Epoch  409\n",
      "Epoch: 409/500 cost: 62.105986304\n",
      "TRAIN ACCURACY: 0.086\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  410\n",
      "#Epoch  411\n",
      "#Epoch  412\n",
      "#Epoch  413\n",
      "#Epoch  414\n",
      "Epoch: 414/500 cost: 62.105986375\n",
      "TRAIN ACCURACY: 0.023\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  415\n",
      "#Epoch  416\n",
      "#Epoch  417\n",
      "#Epoch  418\n",
      "#Epoch  419\n",
      "Epoch: 419/500 cost: 62.105986357\n",
      "TRAIN ACCURACY: 0.117\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  420\n",
      "#Epoch  421\n",
      "#Epoch  422\n",
      "#Epoch  423\n",
      "#Epoch  424\n",
      "Epoch: 424/500 cost: 62.105986322\n",
      "TRAIN ACCURACY: 0.094\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  425\n",
      "#Epoch  426\n",
      "#Epoch  427\n",
      "#Epoch  428\n",
      "#Epoch  429\n",
      "Epoch: 429/500 cost: 62.105986144\n",
      "TRAIN ACCURACY: 0.094\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  430\n",
      "#Epoch  431\n",
      "#Epoch  432\n",
      "#Epoch  433\n",
      "#Epoch  434\n",
      "Epoch: 434/500 cost: 62.105986393\n",
      "TRAIN ACCURACY: 0.078\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  435\n",
      "#Epoch  436\n",
      "#Epoch  437\n",
      "#Epoch  438\n",
      "#Epoch  439\n",
      "Epoch: 439/500 cost: 62.105986304\n",
      "TRAIN ACCURACY: 0.094\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  440\n",
      "#Epoch  441\n",
      "#Epoch  442\n",
      "#Epoch  443\n",
      "#Epoch  444\n",
      "Epoch: 444/500 cost: 62.105986482\n",
      "TRAIN ACCURACY: 0.102\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  445\n",
      "#Epoch  446\n",
      "#Epoch  447\n",
      "#Epoch  448\n",
      "#Epoch  449\n",
      "Epoch: 449/500 cost: 62.105986322\n",
      "TRAIN ACCURACY: 0.102\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  450\n",
      "#Epoch  451\n",
      "#Epoch  452\n",
      "#Epoch  453\n",
      "#Epoch  454\n",
      "Epoch: 454/500 cost: 62.105986179\n",
      "TRAIN ACCURACY: 0.070\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  455\n",
      "#Epoch  456\n",
      "#Epoch  457\n",
      "#Epoch  458\n",
      "#Epoch  459\n",
      "Epoch: 459/500 cost: 62.105986340\n",
      "TRAIN ACCURACY: 0.141\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  460\n",
      "#Epoch  461\n",
      "#Epoch  462\n",
      "#Epoch  463\n",
      "#Epoch  464\n",
      "Epoch: 464/500 cost: 62.105986357\n",
      "TRAIN ACCURACY: 0.109\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  465\n",
      "#Epoch  466\n",
      "#Epoch  467\n",
      "#Epoch  468\n",
      "#Epoch  469\n",
      "Epoch: 469/500 cost: 62.105986322\n",
      "TRAIN ACCURACY: 0.078\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  470\n",
      "#Epoch  471\n",
      "#Epoch  472\n",
      "#Epoch  473\n",
      "#Epoch  474\n",
      "Epoch: 474/500 cost: 62.105986162\n",
      "TRAIN ACCURACY: 0.109\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  475\n",
      "#Epoch  476\n",
      "#Epoch  477\n",
      "#Epoch  478\n",
      "#Epoch  479\n",
      "Epoch: 479/500 cost: 62.105986446\n",
      "TRAIN ACCURACY: 0.109\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  480\n",
      "#Epoch  481\n",
      "#Epoch  482\n",
      "#Epoch  483\n",
      "#Epoch  484\n",
      "Epoch: 484/500 cost: 62.105986251\n",
      "TRAIN ACCURACY: 0.078\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  485\n",
      "#Epoch  486\n",
      "#Epoch  487\n",
      "#Epoch  488\n",
      "#Epoch  489\n",
      "Epoch: 489/500 cost: 62.105986375\n",
      "TRAIN ACCURACY: 0.086\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  490\n",
      "#Epoch  491\n",
      "#Epoch  492\n",
      "#Epoch  493\n",
      "#Epoch  494\n",
      "Epoch: 494/500 cost: 62.105986233\n",
      "TRAIN ACCURACY: 0.109\n",
      "TEST ACCURACY: 0.098\n",
      "#Epoch  495\n",
      "#Epoch  496\n",
      "#Epoch  497\n",
      "#Epoch  498\n",
      "#Epoch  499\n",
      "Epoch: 499/500 cost: 62.105986428\n",
      "TRAIN ACCURACY: 0.055\n",
      "TEST ACCURACY: 0.098\n",
      "OPTIMIZATION FINISHED\n"
     ]
    }
   ],
   "source": [
    "# run it!\n",
    "epochs = 500\n",
    "batch_size      = 128\n",
    "display_step    = 5\n",
    "# LAUNCH THE GRAPH\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print \"init run done\"\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "print \"total batch \", total_batch\n",
    "\n",
    "# OPTIMIZE\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0.\n",
    "    print \"#Epoch \", epoch\n",
    "    \n",
    "    # ITERATION\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.T\n",
    "        batch_ys = batch_ys.T\n",
    "        feeds = {x: batch_xs, y: batch_ys}\n",
    "        sess.run(optm, feed_dict=feeds)\n",
    "        feeds = {x: batch_xs, y: batch_ys}\n",
    "        avg_cost += sess.run(cost, feed_dict=feeds)\n",
    "    avg_cost = avg_cost / total_batch\n",
    "    \n",
    "    # DISPLAY\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, epochs, avg_cost))\n",
    "        feeds = {x: batch_xs, y: batch_ys}\n",
    "        train_acc = sess.run(accr, feed_dict=feeds)\n",
    "        print (\"TRAIN ACCURACY: %.3f\" % (train_acc))\n",
    "        feeds = {x: mnist.test.images.T, y: mnist.test.labels.T}\n",
    "        test_acc = sess.run(accr, feed_dict=feeds)\n",
    "        print (\"TEST ACCURACY: %.3f\" % (test_acc))\n",
    "                \n",
    "print (\"OPTIMIZATION FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
