{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# practise the cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline\n",
    "\n",
    "mnist = input_data.read_data_sets('../data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 layer with max pool  build done, output [, 14, 14, 32]\n",
      "conv2 layer with max pool  build done, output [, 7, 7, 64]\n",
      "conv3 layer with max pool  build done, output [, 4, 4, 128]\n",
      "cost and optimzer build done\n",
      "compute graph ready!\n"
     ]
    }
   ],
   "source": [
    "# build the graph: conv1, fc1, softmax\n",
    "n_input = 28 * 28 * 1\n",
    "n_classes = 10\n",
    "x = tf.placeholder(tf.float32, shape=[None, n_input])\n",
    "y = tf.placeholder(tf.float32, shape=[None, n_classes])\n",
    "x_ = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# conv1 layer\n",
    "conv1_n = 32\n",
    "filter_size = 3\n",
    "conv1 = {\"weight\": tf.Variable(tf.truncated_normal([filter_size, filter_size, 1, conv1_n], stddev=0.1)), \n",
    "        \"bias\": tf.Variable(tf.truncated_normal([1, conv1_n], stddev=0.1))}\n",
    "\n",
    "conv1_z = tf.nn.conv2d(x_, conv1[\"weight\"], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "conv1_a = tf.nn.relu(conv1_z + conv1[\"bias\"])\n",
    "pool1_a = tf.nn.max_pool(conv1_a, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "print \"conv1 layer with max pool  build done, output [, 14, 14, 32]\"\n",
    "\n",
    "# conv2 layer\n",
    "conv2_n = 64\n",
    "filter_size = 3\n",
    "conv2 = {\"weight\": tf.Variable(tf.truncated_normal([filter_size, filter_size, conv1_n, conv2_n], stddev=0.1)), \n",
    "    \"bias\": tf.Variable(tf.truncated_normal([1, conv2_n], stddev=0.1))}\n",
    "\n",
    "conv2_z = tf.nn.conv2d(pool1_a, conv2[\"weight\"], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "conv2_a = tf.nn.relu(conv2_z + conv2[\"bias\"])\n",
    "pool2_a = tf.nn.max_pool(conv2_a, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "print \"conv2 layer with max pool  build done, output [, 7, 7, 64]\"\n",
    "width = 7\n",
    "nodes = conv2_n\n",
    "outting = pool2_a\n",
    "\n",
    "# dropout layer\n",
    "outting = tf.nn.dropout(outting, keep_prob)\n",
    "\n",
    "# conv3 layer\n",
    "conv3_n = 64 * 2\n",
    "filter_size = 3\n",
    "conv3 = {\"weight\": tf.Variable(tf.truncated_normal([filter_size, filter_size, conv2_n, conv3_n], stddev=0.1)), \n",
    "    \"bias\": tf.Variable(tf.truncated_normal([1, conv3_n], stddev=0.1))}\n",
    "\n",
    "conv3_z = tf.nn.conv2d(pool2_a, conv3[\"weight\"], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "conv3_a = tf.nn.relu(conv3_z + conv3[\"bias\"])\n",
    "pool3_a = tf.nn.max_pool(conv3_a, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "print \"conv3 layer with max pool  build done, output [, 4, 4, 128]\"\n",
    "width = 4\n",
    "nodes = conv3_n\n",
    "outting = pool3_a\n",
    "\n",
    "# dropout layer\n",
    "outting = tf.nn.dropout(outting, keep_prob)\n",
    "\n",
    "# flat into vector\n",
    "outting = tf.reshape(outting, [-1, nodes * width * width])\n",
    "nodes = nodes * width * width\n",
    "\n",
    "# fc layer\n",
    "# fc1_n = 128\n",
    "# fc1 = {\"weight\": tf.Variable(tf.truncated_normal([nodes * width * width, fc1_n], stddev=0.1)),\n",
    "#       \"bias\": tf.Variable(tf.truncated_normal([1, fc1_n], stddev=0.1))}\n",
    "\n",
    "# fc1_z = tf.add(tf.matmul(flatted, fc1[\"weight\"]), fc1[\"bias\"])\n",
    "# fc1_a = tf.nn.relu(fc1_z)\n",
    "# print \"fc layer build done\"\n",
    "\n",
    "# output layer\n",
    "out = {\"weight\": tf.Variable(tf.truncated_normal([nodes, n_classes], stddev=0.1)),\n",
    "      \"bias\": tf.Variable(tf.truncated_normal([1, n_classes], stddev=0.1))}\n",
    "\n",
    "y_ = tf.nn.softmax(tf.add(tf.matmul(outting, out[\"weight\"]), out[\"bias\"]))\n",
    "\n",
    "# the cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_, labels=y))\n",
    "\n",
    "optm = tf.train.AdamOptimizer().minimize(cost)\n",
    "corr = tf.equal(tf.argmax(y_, 1), tf.argmax(y, 1))\n",
    "accr = tf.reduce_mean(tf.cast(corr, tf.float32))\n",
    "print \"cost and optimzer build done\"\n",
    "print \"compute graph ready!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init run done\n",
      "#Epoch  0\n",
      "Epoch: 000/010 cost: 1.607381572\n",
      "TRAIN ACCURACY: 0.969\n",
      "TEST ACCURACY: 0.972\n",
      "#Epoch  1\n",
      "Epoch: 001/010 cost: 1.489170105\n",
      "TRAIN ACCURACY: 0.977\n",
      "TEST ACCURACY: 0.983\n",
      "#Epoch  2\n",
      "Epoch: 002/010 cost: 1.481952180\n",
      "TRAIN ACCURACY: 0.992\n",
      "TEST ACCURACY: 0.987\n",
      "#Epoch  3\n",
      "Epoch: 003/010 cost: 1.477369847\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "#Epoch  4\n",
      "Epoch: 004/010 cost: 1.476044860\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "#Epoch  5\n",
      "Epoch: 005/010 cost: 1.473342210\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.990\n",
      "#Epoch  6\n",
      "Epoch: 006/010 cost: 1.472104743\n",
      "TRAIN ACCURACY: 0.992\n",
      "TEST ACCURACY: 0.990\n",
      "#Epoch  7\n",
      "Epoch: 007/010 cost: 1.471542617\n",
      "TRAIN ACCURACY: 0.984\n",
      "TEST ACCURACY: 0.992\n",
      "#Epoch  8\n",
      "Epoch: 008/010 cost: 1.471017580\n",
      "TRAIN ACCURACY: 0.992\n",
      "TEST ACCURACY: 0.991\n",
      "#Epoch  9\n",
      "Epoch: 009/010 cost: 1.469936587\n",
      "TRAIN ACCURACY: 0.992\n",
      "TEST ACCURACY: 0.992\n",
      "OPTIMIZATION FINISHED\n"
     ]
    }
   ],
   "source": [
    "# run!\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print \"init run done\"\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "writer = tf.summary.FileWriter('/tmp/tf_logs/cnn-mnist', graph=sess.graph)\n",
    "tf.summary.scalar(\"accuracy\", accr)\n",
    "summaries = tf.summary.merge_all()\n",
    "\n",
    "j = 0\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0.\n",
    "    print \"#Epoch \", epoch\n",
    "    \n",
    "    # ITERATION\n",
    "    for i in range(total_batch):\n",
    "        j += 1\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feeds = {x: batch_xs, y: batch_ys, keep_prob: 0.8}\n",
    "        _, percost = sess.run([optm, cost], feed_dict=feeds)\n",
    "        avg_cost += percost\n",
    "#         writer.add_summary(summary, j)\n",
    "    avg_cost = avg_cost / total_batch\n",
    "    \n",
    "    # DISPLAY\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, epochs, avg_cost))\n",
    "        feeds = {x: batch_xs, y: batch_ys, keep_prob: 1}\n",
    "        train_acc, = sess.run([accr], feed_dict=feeds)\n",
    "        print (\"TRAIN ACCURACY: %.3f\" % (train_acc))\n",
    "#         writer.add_summary(summary_train, epoch)\n",
    "        feeds = {x: mnist.test.images, y: mnist.test.labels, keep_prob: 1}\n",
    "        test_acc = sess.run(accr, feed_dict=feeds)\n",
    "#         writer.add_summary(test_acc,)\n",
    "        print (\"TEST ACCURACY: %.3f\" % (test_acc))\n",
    "                \n",
    "print (\"OPTIMIZATION FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
