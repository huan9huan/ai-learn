{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# give a seqence, and guess next ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 with 1d build done\n",
      "fc1 layer build done\n",
      "layer 4 build done \n",
      "compute graph ready!\n"
     ]
    }
   ],
   "source": [
    "# build the graph\n",
    "LEN = 7\n",
    "n_classes = 3 # guess which value Left will output?\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, LEN, 2])\n",
    "y = tf.placeholder(tf.float32, shape=[None, n_classes])\n",
    "\n",
    "# layer 1: conv1d\n",
    "conv1_n = 32 # filter count is 32\n",
    "conv1 = {\"weight\": tf.Variable(tf.truncated_normal([3, 2, conv1_n] ,stddev=0.1)),\n",
    "        \"bias\": tf.Variable(tf.truncated_normal([1, conv1_n], stddev=0.1))}\n",
    "\n",
    "conv1_z = tf.nn.conv1d(x, conv1[\"weight\"], stride=1, padding=\"SAME\")\n",
    "conv1_a = tf.nn.relu(conv1_z + conv1[\"bias\"])\n",
    "print \"conv1 with 1d build done\"\n",
    "\n",
    "# layer 2: fc\n",
    "# reshape into vector\n",
    "nodes = conv1_n * LEN\n",
    "fc1_input = tf.reshape(conv1_a, [-1, nodes])\n",
    "\n",
    "fc1_n = 32\n",
    "fc1 = {\"weight\": tf.Variable(tf.truncated_normal([nodes, fc1_n], stddev=0.1)),\n",
    "     \"bias\": tf.Variable(tf.truncated_normal([1, fc1_n]))}\n",
    "fc1_z = tf.add(tf.matmul(fc1_input, fc1[\"weight\"]), fc1[\"bias\"])\n",
    "fc1_a = tf.nn.relu(fc1_z)\n",
    "nodes = fc1_n\n",
    "print \"fc1 layer build done\"\n",
    "\n",
    "# layer 3: softmax\n",
    "out = {\"weight\": tf.Variable(tf.truncated_normal([nodes, n_classes], stddev=0.1)),\n",
    "      \"bias\": tf.Variable(tf.truncated_normal([1, n_classes], stddev=0.1))}\n",
    "\n",
    "print \"layer 4 build done \"\n",
    "outting = fc1_a\n",
    "y_ = tf.nn.softmax(tf.add(tf.matmul(outting, out[\"weight\"]), out[\"bias\"]))\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_, labels=y))\n",
    "\n",
    "optm = tf.train.AdamOptimizer().minimize(cost)\n",
    "corr = tf.equal(tf.argmax(y_, 1), tf.argmax(y, 1))\n",
    "accr = tf.reduce_mean(tf.cast(corr, tf.float32))\n",
    "# pred = tf.argmax(y_, 1)\n",
    "\n",
    "print \"compute graph ready!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x shape (700, 7, 2)\n",
      "train Y shape (700, 3)\n",
      "TEST x shape (190, 7, 2)\n",
      "TEST y shape (190, 3)\n"
     ]
    }
   ],
   "source": [
    "# build the rules\n",
    "def score(l, r):\n",
    "    return 1 if r > l else -1 if r < l else 0\n",
    "    \n",
    "# run a random sequence\n",
    "def sample(cnt):\n",
    "    seq = []\n",
    "    ls = np.random.randint(2, size=cnt)\n",
    "    rs = np.random.randint(3, size=cnt)\n",
    "    for i in range(cnt):\n",
    "        seq.append([ls[i], score(ls[i], rs[i])])\n",
    "    return seq\n",
    "\n",
    "## generate the data\n",
    "def gen(all, since, cnt, window):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(since, since + cnt):\n",
    "        x = all[i: i+window, :]\n",
    "        X.append(x)\n",
    "        y = [0, 0, 0]\n",
    "        val = all[i + window][0]\n",
    "        y[val] = 1\n",
    "        Y.append(y)\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "total = 1000\n",
    "train_x_count = 700\n",
    "test_count = 190\n",
    "seq = np.array(sample(total))\n",
    "\n",
    "train_X, train_Y = gen(seq, 0, train_x_count, LEN)\n",
    "test_X, test_Y = gen(seq, train_x_count, test_count, LEN)\n",
    "\n",
    "print \"train x shape\", train_X.shape # should be [70, 7, 2]\n",
    "print \"train Y shape\", train_Y.shape # should be [70, 3]\n",
    "print \"TEST x shape\", test_X.shape # should be [18, 7, 2]\n",
    "print \"TEST y shape\", test_Y.shape # should be [18, 3]\n",
    "\n",
    "assert(np.argmax(train_Y[0, :]) == seq[LEN, 0])\n",
    "assert(np.argmax(train_Y[1, :]) == seq[LEN + 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init run done\n",
      "train x shape (700, 7, 2)\n",
      "train y shape (700, 3)\n",
      "Epoch 0 accuracy (train vs. test) 0.0 0.0\n",
      "Epoch 10 accuracy (train vs. test) 0.491429 0.5\n",
      "Epoch 20 accuracy (train vs. test) 0.525714 0.473684\n",
      "Epoch 30 accuracy (train vs. test) 0.531429 0.484211\n",
      "Epoch 40 accuracy (train vs. test) 0.515714 0.463158\n",
      "Epoch 50 accuracy (train vs. test) 0.514286 0.473684\n",
      "Epoch 60 accuracy (train vs. test) 0.528571 0.447368\n",
      "Epoch 70 accuracy (train vs. test) 0.554286 0.447368\n",
      "Epoch 80 accuracy (train vs. test) 0.56 0.426316\n",
      "Epoch 90 accuracy (train vs. test) 0.575714 0.452632\n",
      "Epoch 100 accuracy (train vs. test) 0.588571 0.457895\n",
      "Epoch 110 accuracy (train vs. test) 0.588571 0.468421\n",
      "Epoch 120 accuracy (train vs. test) 0.585714 0.463158\n",
      "Epoch 130 accuracy (train vs. test) 0.592857 0.478947\n",
      "Epoch 140 accuracy (train vs. test) 0.605714 0.494737\n",
      "Epoch 150 accuracy (train vs. test) 0.62 0.494737\n",
      "Epoch 160 accuracy (train vs. test) 0.608571 0.505263\n",
      "Epoch 170 accuracy (train vs. test) 0.625714 0.489474\n",
      "Epoch 180 accuracy (train vs. test) 0.631429 0.489474\n",
      "Epoch 190 accuracy (train vs. test) 0.638571 0.505263\n",
      "Epoch 200 accuracy (train vs. test) 0.652857 0.5\n",
      "Epoch 210 accuracy (train vs. test) 0.668571 0.494737\n",
      "Epoch 220 accuracy (train vs. test) 0.661429 0.515789\n",
      "Epoch 230 accuracy (train vs. test) 0.662857 0.510526\n",
      "Epoch 240 accuracy (train vs. test) 0.675714 0.515789\n",
      "Epoch 250 accuracy (train vs. test) 0.678571 0.494737\n",
      "Epoch 260 accuracy (train vs. test) 0.685714 0.494737\n",
      "Epoch 270 accuracy (train vs. test) 0.7 0.505263\n",
      "Epoch 280 accuracy (train vs. test) 0.71 0.505263\n",
      "Epoch 290 accuracy (train vs. test) 0.72 0.5\n",
      "Epoch 300 accuracy (train vs. test) 0.725714 0.505263\n",
      "Epoch 310 accuracy (train vs. test) 0.731429 0.5\n",
      "Epoch 320 accuracy (train vs. test) 0.738571 0.494737\n",
      "Epoch 330 accuracy (train vs. test) 0.747143 0.505263\n",
      "Epoch 340 accuracy (train vs. test) 0.751429 0.505263\n",
      "Epoch 350 accuracy (train vs. test) 0.767143 0.510526\n",
      "Epoch 360 accuracy (train vs. test) 0.772857 0.505263\n",
      "Epoch 370 accuracy (train vs. test) 0.788571 0.521053\n",
      "Epoch 380 accuracy (train vs. test) 0.795714 0.505263\n",
      "Epoch 390 accuracy (train vs. test) 0.802857 0.5\n",
      "Epoch 400 accuracy (train vs. test) 0.807143 0.505263\n",
      "Epoch 410 accuracy (train vs. test) 0.807143 0.5\n",
      "Epoch 420 accuracy (train vs. test) 0.81 0.5\n",
      "Epoch 430 accuracy (train vs. test) 0.817143 0.5\n",
      "Epoch 440 accuracy (train vs. test) 0.824286 0.494737\n",
      "Epoch 450 accuracy (train vs. test) 0.828571 0.494737\n",
      "Epoch 460 accuracy (train vs. test) 0.834286 0.494737\n",
      "Epoch 470 accuracy (train vs. test) 0.841429 0.494737\n",
      "Epoch 480 accuracy (train vs. test) 0.842857 0.489474\n",
      "Epoch 490 accuracy (train vs. test) 0.848571 0.494737\n",
      "Epoch 500 accuracy (train vs. test) 0.852857 0.5\n",
      "Epoch 510 accuracy (train vs. test) 0.855714 0.494737\n",
      "Epoch 520 accuracy (train vs. test) 0.861429 0.505263\n",
      "Epoch 530 accuracy (train vs. test) 0.862857 0.489474\n",
      "Epoch 540 accuracy (train vs. test) 0.874286 0.5\n",
      "Epoch 550 accuracy (train vs. test) 0.875714 0.5\n",
      "Epoch 560 accuracy (train vs. test) 0.881429 0.5\n",
      "Epoch 570 accuracy (train vs. test) 0.884286 0.521053\n",
      "Epoch 580 accuracy (train vs. test) 0.885714 0.515789\n",
      "Epoch 590 accuracy (train vs. test) 0.888571 0.521053\n",
      "Epoch 600 accuracy (train vs. test) 0.89 0.526316\n",
      "Epoch 610 accuracy (train vs. test) 0.891429 0.536842\n",
      "Epoch 620 accuracy (train vs. test) 0.894286 0.531579\n",
      "Epoch 630 accuracy (train vs. test) 0.894286 0.531579\n",
      "Epoch 640 accuracy (train vs. test) 0.895714 0.531579\n",
      "Epoch 650 accuracy (train vs. test) 0.9 0.531579\n",
      "Epoch 660 accuracy (train vs. test) 0.9 0.526316\n",
      "Epoch 670 accuracy (train vs. test) 0.9 0.526316\n",
      "Epoch 680 accuracy (train vs. test) 0.902857 0.526316\n",
      "Epoch 690 accuracy (train vs. test) 0.902857 0.526316\n",
      "Epoch 700 accuracy (train vs. test) 0.902857 0.526316\n",
      "Epoch 710 accuracy (train vs. test) 0.902857 0.531579\n",
      "Epoch 720 accuracy (train vs. test) 0.902857 0.531579\n",
      "Epoch 730 accuracy (train vs. test) 0.904286 0.536842\n",
      "Epoch 740 accuracy (train vs. test) 0.904286 0.531579\n",
      "Epoch 750 accuracy (train vs. test) 0.904286 0.526316\n",
      "Epoch 760 accuracy (train vs. test) 0.904286 0.526316\n",
      "Epoch 770 accuracy (train vs. test) 0.905714 0.526316\n",
      "Epoch 780 accuracy (train vs. test) 0.908571 0.526316\n",
      "Epoch 790 accuracy (train vs. test) 0.908571 0.526316\n",
      "Epoch 800 accuracy (train vs. test) 0.908571 0.531579\n",
      "Epoch 810 accuracy (train vs. test) 0.91 0.531579\n",
      "Epoch 820 accuracy (train vs. test) 0.91 0.526316\n",
      "Epoch 830 accuracy (train vs. test) 0.91 0.531579\n",
      "Epoch 840 accuracy (train vs. test) 0.91 0.531579\n",
      "Epoch 850 accuracy (train vs. test) 0.91 0.531579\n",
      "Epoch 860 accuracy (train vs. test) 0.91 0.542105\n",
      "Epoch 870 accuracy (train vs. test) 0.91 0.531579\n",
      "Epoch 880 accuracy (train vs. test) 0.91 0.531579\n",
      "Epoch 890 accuracy (train vs. test) 0.91 0.531579\n",
      "Epoch 900 accuracy (train vs. test) 0.91 0.531579\n",
      "Epoch 910 accuracy (train vs. test) 0.91 0.531579\n",
      "Epoch 920 accuracy (train vs. test) 0.91 0.531579\n",
      "Epoch 930 accuracy (train vs. test) 0.91 0.531579\n",
      "Epoch 940 accuracy (train vs. test) 0.91 0.531579\n",
      "Epoch 950 accuracy (train vs. test) 0.91 0.526316\n",
      "Epoch 960 accuracy (train vs. test) 0.911429 0.526316\n",
      "Epoch 970 accuracy (train vs. test) 0.911429 0.526316\n",
      "Epoch 980 accuracy (train vs. test) 0.911429 0.521053\n",
      "Epoch 990 accuracy (train vs. test) 0.911429 0.521053\n"
     ]
    }
   ],
   "source": [
    "# run\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print \"init run done\"\n",
    "\n",
    "print \"train x shape\", train_X.shape\n",
    "print \"train y shape\", train_Y.shape\n",
    "epochs = 1000\n",
    "print_step = 10\n",
    "for epoch in range(epochs):\n",
    "    feeds = {x: train_X, y: train_Y}\n",
    "    sess.run([optm], feed_dict=feeds)\n",
    "\n",
    "    # predict in test dataset\n",
    "    if epoch % print_step == 0:\n",
    "        feeds = {x: train_X, y: train_Y}\n",
    "        train_accr = sess.run(accr, feed_dict=feeds)\n",
    "        feeds = {x: test_X, y: test_Y}\n",
    "        test_accr = sess.run(accr, feed_dict=feeds)\n",
    "        print \"Epoch %s accuracy (train vs. test)\" %epoch, train_accr, test_accr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
